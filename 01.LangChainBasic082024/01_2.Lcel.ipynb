{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain Expression Language(LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PROMPT + MODEL + PARSER\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Project1\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('Project1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PromptTemplate : 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿\n",
    "\n",
    "    - template : 템플릿 문자열 / {}문자열 내에서 중괄호 는 변수\n",
    "    \n",
    "    - input_variables : 중괄호 안에 들어갈 변수의 이름을 리스트로 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country} 의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{country} 의 수도는 어디인가요?\"\n",
    "#from_template() 메소드로 PromptTemplate객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국 의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create prompt\n",
    "prompt = prompt_template.format( country = '대한민국')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chulwonchae/FullStack_GPT/env/lib/python3.10/site-packages/langchain_core/utils/utils.py:235: UserWarning: WARNING! temperatue is not default parameter.\n",
      "                temperatue was transferred to model_kwargs.\n",
      "                Please confirm that temperatue is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    max_tokens=2048,\n",
    "    temperatue = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke()\n",
    "- Python dictionary형태로 input값을 전달 (key : value)\n",
    "- invoke()함수 호출시, 입력값을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 주어진 데이터를 사용하여 모델이 일정한 규칙이나 패턴을 학습하는 과정을 말합니다. \\n\\n이 학습 과정은 크게 입력 데이터를 받아들이고, 이를 처리하여 원하는 출력을 만들어내는 과정으로 나뉩니다. 모델은 입력 데이터를 받아들이고, 이를 처리하여 예측값을 출력합니다. 이때 모델은 입력 데이터와 예측값의 차이를 최소화하는 방향으로 스스로를 개선해나갑니다. \\n\\n모델이 학습을 통해 최적의 가중치와 편향을 찾아내고, 새로운 데이터가 들어왔을 때 정확한 예측을 할 수 있도록 합니다. 이러한 과정을 반복하여 모델은 점차 데이터에 대한 이해력을 키우고, 높은 정확도로 예측을 수행할 수 있게 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 285, 'prompt_tokens': 33, 'total_tokens': 318}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-099c456d-c534-43fb-a4c6-1fa0e04d78d9-0', usage_metadata={'input_tokens': 33, 'output_tokens': 285, 'total_tokens': 318})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input) # connect prompt and model with | and transfer input by invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = chain.stream(input)\n",
    "# stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 내부적으로 학습 알고리즘을 사용하여 데이터의 패턴을 학습하는 과정입니다.\\n\\n먼저, 모델은 입력 데이터를 받아들이고 이를 처리하기 위한 다양한 가중치와 편향을 가지고 있습니다. 이 가중치와 편향은 초기에는 랜덤한 값으로 설정되어 있습니다.\\n\\n그 다음, 입력 데이터를 모델에 주입하여 출력을 얻습니다. 이 출력은 모델이 현재까지 학습한 결과를 나타냅니다. 이 출력과 실제 정답을 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 모델의 가중치와 편향을 조정합니다.\\n\\n이렇게 반복적으로 오차를 최소화하는 방향으로 모델을 업데이트하면서 학습을 진행합니다. 이 과정을 반복하면 모델은 입력 데이터의 패턴을 점점 더 잘 이해하고 정확한 결과를 예측할 수 있도록 학습됩니다. 이러한 과정을 통해 모델은 학습 데이터에 대해 높은 정확도를 가지게 됩니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)\n",
    "# 정답만 깔끔하게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = chain.stream(input)\n",
    "# stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply with changed template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Investing Asset Class: Equities \n",
      "- Investing Weight: 70% \n",
      "- Rest of your asset: 30% in fixed income and cash equivalents\n"
     ]
    }
   ],
   "source": [
    "template =  '''\n",
    "You are a 10 years of experienced CFA. Answer properly in English.\n",
    "Refer to the [FORMAT] below.\n",
    "\n",
    "# Situation :\n",
    "{question}\n",
    "\n",
    "#FORMAT\n",
    "- Investing Asset Class:\n",
    "- Investing Weight :\n",
    "- Rest of your asset : \n",
    "\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "print(chain.invoke({'question':'I am going to retire next year I would like to invest aggresive'}))\n",
    "#answer = chain.stream({'question':'I am going to retire next year I would like to invest aggresive'})\n",
    "#stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20079dd2ac21832bb0e8ff352d23b6c3837ca9c91609572aa5b291e173833a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
