{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In our solar system, there are eight planets: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, there are potentially thousands of exoplanets in other solar systems beyond our own.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI #llm 모델 선택 (davinci 는 비싸)\n",
    "from langchain.chat_models import ChatOpenAI #chat 모델 선택, #ChatAnthropic\n",
    "\n",
    "#llm = OpenAI()\n",
    "chat = ChatOpenAI() # ChatAnthropic() 모델 바로 바꿀수 있어\n",
    "# chat모델은 chat에 특화\n",
    "# a = llm.predict(\"How many planets are there\")\n",
    "b = chat.predict(\"How many planets are there\") \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles). My name is Assistant.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI #chat 모델 선택, #ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate #ChatPromptTemplate : 은 아래 'messages'로 부터 프롬프트를 만들고 / PromptTemplate : 은 string으로부터 만듬\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "prompt = template.format(place_a='Mexico', place_b='Thailand')\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict message\n",
    "# from langchain.schema import HumanMessage, AIMessage, SystemMessage #system message : 우리가 llm설정들을 제공하기 위한 message\n",
    "# messages = [\n",
    "#     SystemMessage(content = \"You are a geography expert. And you only reply in {language}\"),\n",
    "#     AIMessage(content = \"안녕하세요, 저는 대한민국 대동여지도를 만든 {name} 입니다.\"),\n",
    "#     HumanMessage(content = \"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "# ]\n",
    "\n",
    "# chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Το όνομά μου είναι Σωκράτης. Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tempplate 생성\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}\"),\n",
    "    (\"ai\", \"안녕하세요, 저는 대한민국 대동여지도를 만든 {name} 입니다.\"),\n",
    "    (\"human\", \"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language = \"Greek\",\n",
    "    name = \"Socrates\",\n",
    "    place_a = \"Mexico\",\n",
    "    place_b = \"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Parser필요한 이유는 llm의 응답을 변형해야할 때가 있기 때문 (리스트로 변환하던지)\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self,text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello,how, are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "     (\"human\",\"{question}\"),]\n",
    ")\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the colors?\")\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu', 'Charmander', 'Bulbasaur', 'Squirtle', 'Jigglypuff']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better way.\n",
    "# 코드를 다시 정리 해보자 (여기서 부터 코드 다시 돌려봐)\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self,text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "     (\"human\",\"{question}\"),]\n",
    ")\n",
    "\n",
    "# Chain을 만들거야\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({  #chain 실행, dictionary형태로\n",
    "    \"max_items\" : 5,\n",
    "    \"question\" : \"What are the Pokemons\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 chain = chain +chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any types of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and delicious recipe for Chicken Tikka Masala. Here's how you can make it at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons paprika\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated fresh ginger\n",
      "- Salt and pepper to taste\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (to serve)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, combine the yogurt, lemon juice, cumin, paprika, turmeric, garam masala, coriander, chili powder, garlic, ginger, salt, and pepper. Add the chicken pieces and mix until well coated. Cover and marinate in the refrigerator for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. In a large skillet or pan, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened and translucent.\n",
      "\n",
      "3. Add the marinated chicken pieces to the skillet, along with any remaining marinade. Cook for about 5-7 minutes, stirring occasionally, until the chicken is browned on all sides.\n",
      "\n",
      "4. Pour in the tomato sauce and stir to combine. Bring the mixture to a simmer, then reduce the heat to low. Cover and cook for about 15-20 minutes, or until the chicken is cooked through.\n",
      "\n",
      "5. Stir in the heavy cream and simmer for an additional 5 minutes, allowing the flavors to meld together. Taste and adjust seasoning if needed.\n",
      "\n",
      "6. Serve the Chicken Tikka Masala hot over cooked rice or with naan bread. Garnish with fresh cilantro before serving.\n",
      "\n",
      "Enjoy your homemade Chicken Tikka Masala, a popular Indian dish that's sure to impress your family and friends!As a vegetarian chef, I can help you make a vegetarian version of Chicken Tikka Masala by replacing the chicken with a suitable alternative. In this case, you can use paneer, a type of Indian cottage cheese that is commonly used in vegetarian dishes as a substitute for meat. Here's how you can modify the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb paneer, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons paprika\n",
      "- 1 teaspoon ground turmeric\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated fresh ginger\n",
      "- Salt and pepper to taste\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (to serve)\n",
      "\n",
      "Instructions:\n",
      "1. Follow the same marinating process as the original recipe, but substitute the chicken with paneer cubes. Marinate the paneer in the yogurt and spice mixture for at least 1 hour.\n",
      "2. In step 2, sauté the onion in vegetable oil until softened before adding the marinated paneer to the skillet.\n",
      "3. Cook the paneer until browned on all sides, following the same cooking time as you would for chicken.\n",
      "4. Continue with the recipe as directed, simmering the tomato sauce with the paneer and adding the heavy cream to finish the dish.\n",
      "5. Serve the Vegetarian Tikka Masala hot over rice or with naan bread, garnished with fresh cilantro.\n",
      "\n",
      "By making this simple substitution, you can enjoy a flavorful and satisfying Vegetarian Tikka Masala that stays true to the essence of the traditional dish. Enjoy your meat-free version of this classic Indian recipe!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"As a vegetarian chef, I can help you make a vegetarian version of Chicken Tikka Masala by replacing the chicken with a suitable alternative. In this case, you can use paneer, a type of Indian cottage cheese that is commonly used in vegetarian dishes as a substitute for meat. Here's how you can modify the recipe:\\n\\nIngredients:\\n- 1 lb paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt\\n- 2 tablespoons lemon juice\\n- 2 teaspoons ground cumin\\n- 2 teaspoons paprika\\n- 1 teaspoon ground turmeric\\n- 1 teaspoon garam masala\\n- 1 teaspoon ground coriander\\n- 1 teaspoon chili powder (adjust to taste)\\n- 3 cloves garlic, minced\\n- 1 tablespoon grated fresh ginger\\n- Salt and pepper to taste\\n- 2 tablespoons vegetable oil\\n- 1 onion, finely chopped\\n- 1 can (14 oz) tomato sauce\\n- 1 cup heavy cream\\n- Fresh cilantro, chopped (for garnish)\\n- Cooked rice or naan bread (to serve)\\n\\nInstructions:\\n1. Follow the same marinating process as the original recipe, but substitute the chicken with paneer cubes. Marinate the paneer in the yogurt and spice mixture for at least 1 hour.\\n2. In step 2, sauté the onion in vegetable oil until softened before adding the marinated paneer to the skillet.\\n3. Cook the paneer until browned on all sides, following the same cooking time as you would for chicken.\\n4. Continue with the recipe as directed, simmering the tomato sauce with the paneer and adding the heavy cream to finish the dish.\\n5. Serve the Vegetarian Tikka Masala hot over rice or with naan bread, garnished with fresh cilantro.\\n\\nBy making this simple substitution, you can enjoy a flavorful and satisfying Vegetarian Tikka Masala that stays true to the essence of the traditional dish. Enjoy your meat-free version of this classic Indian recipe!\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modifiy the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain # \"recipe\" context object를 체인에 넣어줘 (아래 코드 안쓰고, recipe 값에 결과 저장 후, 다음 체인으로 전달)\n",
    "final_chain.invoke({ \n",
    "    \"cuisine\":\"indian\"\n",
    "})\n",
    "\n",
    "#\"recipe\": chef_chain 이것을 함으로서 자동으로 veg_chain.invoke() 가 돌아가는 것임\n",
    "\n",
    "# # 즉, chef_chain의 결과 {recipe}를 veg_chain의 input 으로..\n",
    "# veg_chain.invoke({\n",
    "#     \"recipe\":\"chatmodel\" #이런식으로\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모듈\n",
    "# LangChain은 다음과 같은 주요 모듈을 위한 확장 가능한 표준 인터페이스 및 외부 통합 기능을 제공합니다:\n",
    "\n",
    "# - Model I/O\n",
    "# 언어 모델과의 인터페이스\n",
    "\n",
    "# - Retrieval\n",
    "# 애플리케이션별 데이터를 사용한 인터페이스\n",
    "\n",
    "# - Agents\n",
    "# 높은 수준의 지침이 주어지면 체인이 어떤 도구를 사용할지 선택하도록 합니다\n",
    "\n",
    "# - Chains\n",
    "# 일반적인 빌딩 블록 구성\n",
    "\n",
    "# - Memory\n",
    "# 체인 실행 간 지속적인 응용 프로그램 상태\n",
    "\n",
    "# - Callbacks\n",
    "# 모든 체인의 중간 단계 기록 및 스트리밍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# few shot \n",
    "# you are giving examples to model how to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #이 형식도 똑같아 (langchain document way)\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatMessagePromptTemplate\n",
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1, # 낮을수록 창의적\n",
    "#     streaming=True,  # 실시간으로 글자 보여줘 \n",
    "#     callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "# t = PromptTemplate(\n",
    "#     template = \"What is the capital of {country}\",\n",
    "#     input_variables = ['country'])\n",
    "\n",
    "# t.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        I know the following:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        I know the following:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "#format examples\n",
    "# example_template = \"\"\"Human: {question} AI : {answer}\"\"\"\n",
    "# example_prompt = PromptTemplate.from_template(example_template)\n",
    "# or just \n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI : {answer}\")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    "    suffix = \"Human: What do you know about {country}?\", #example 다 넣고, question of user\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "#prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"country\":\"Germany\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro\\n        ')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatprompt templete 사용해보기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\", # 참고\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt =  ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"human\", \"What do you know about {country}?\"), #위 참고 가 country\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "chain.invoke({\"country\":\"Germany\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#example\u001b[39;00m\n\u001b[1;32m     15\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     {\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you know about France?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     },\n\u001b[1;32m     46\u001b[0m ]\n\u001b[0;32m---> 48\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m AI : \u001b[39m\u001b[38;5;132;01m{answer}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m LengthBasedExampleSelector(\n\u001b[1;32m     51\u001b[0m     examples\u001b[38;5;241m=\u001b[39mexamples,\n\u001b[1;32m     52\u001b[0m     example_prompt\u001b[38;5;241m=\u001b[39mexample_prompt,\n\u001b[1;32m     53\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m prompt \u001b[38;5;241m=\u001b[39m FewShotPromptTemplate( \n\u001b[1;32m     57\u001b[0m     example_prompt \u001b[38;5;241m=\u001b[39m example_prompt,\n\u001b[1;32m     58\u001b[0m     example_selector\u001b[38;5;241m=\u001b[39mexample_selector, \u001b[38;5;66;03m#추가 (이제는 전체 예제를 사용하는게 아니라 selector를 거친 예제들만)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman: What do you know about \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     60\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     61\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "#  Dynamic example selector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector # 예제의 양을 얼마나 되는지 확인하고, 세팅값에 따라 알맞은 prompt예제 골라줄 것임.\n",
    "\n",
    "        \n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI : {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate( \n",
    "    example_prompt = example_prompt,\n",
    "    example_selector=example_selector, #추가 (이제는 전체 예제를 사용하는게 아니라 selector를 거친 예제들만)\n",
    "    suffix = \"Human: What do you know about {country}?\", \n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country='Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dynamic example selector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector # 예제의 양을 얼마나 되는지 확인하고, 세팅값에 따라 알맞은 prompt예제 골라줄 것임.\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector): #랜던으로 예제 선택하는 \n",
    "    \n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example): \n",
    "        self.examples.append(example)\n",
    "    \n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)] #리스트로해서 넣어야하니까 \n",
    "    \n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI : {answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate( \n",
    "    example_prompt = example_prompt,\n",
    "    example_selector=example_selector, #추가 (이제는 전체 예제를 사용하는게 아니라 selector를 거친 예제들만)\n",
    "    suffix = \"Human: What do you know about {country}?\", \n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country='Brazil')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20079dd2ac21832bb0e8ff352d23b6c3837ca9c91609572aa5b291e173833a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
