{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI #llm 모델 선택 (davinci 는 비싸)\n",
    "from langchain.chat_models import ChatOpenAI #chat 모델 선택, #ChatAnthropic\n",
    "\n",
    "#llm = OpenAI()\n",
    "chat = ChatOpenAI() # ChatAnthropic() 모델 바로 바꿀수 있어\n",
    "# chat모델은 chat에 특화\n",
    "# a = llm.predict(\"How many planets are there\")\n",
    "b = chat.predict(\"How many planets are there\") \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles). My name is Assistant.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI #chat 모델 선택, #ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate #ChatPromptTemplate : 은 아래 'messages'로 부터 프롬프트를 만들고 / PromptTemplate : 은 string으로부터 만듬\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "prompt = template.format(place_a='Mexico', place_b='Thailand')\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict message\n",
    "# from langchain.schema import HumanMessage, AIMessage, SystemMessage #system message : 우리가 llm설정들을 제공하기 위한 message\n",
    "# messages = [\n",
    "#     SystemMessage(content = \"You are a geography expert. And you only reply in {language}\"),\n",
    "#     AIMessage(content = \"안녕하세요, 저는 대한민국 대동여지도를 만든 {name} 입니다.\"),\n",
    "#     HumanMessage(content = \"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "# ]\n",
    "\n",
    "# chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Το όνομά μου είναι Σωκράτης. Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tempplate 생성\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}\"),\n",
    "    (\"ai\", \"안녕하세요, 저는 대한민국 대동여지도를 만든 {name} 입니다.\"),\n",
    "    (\"human\", \"What is the distance between {place_a} and {place_b}? Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language = \"Greek\",\n",
    "    name = \"Socrates\",\n",
    "    place_a = \"Mexico\",\n",
    "    place_b = \"Thailand\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Parser필요한 이유는 llm의 응답을 변형해야할 때가 있기 때문 (리스트로 변환하던지)\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self,text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello,how, are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "     (\"human\",\"{question}\"),]\n",
    ")\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the colors?\")\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pikachu', 'Charmander', 'Bulbasaur', 'Squirtle', 'Jigglypuff']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better way.\n",
    "# 코드를 다시 정리 해보자 (여기서 부터 코드 다시 돌려봐)\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self,text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items}. Do NOT reply with anything else.\",),\n",
    "     (\"human\",\"{question}\"),]\n",
    ")\n",
    "\n",
    "# Chain을 만들거야\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({  #chain 실행, dictionary형태로\n",
    "    \"max_items\" : 5,\n",
    "    \"question\" : \"What are the Pokemons\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 chain = chain +chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any types of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and popular Indian dish - Chicken Tikka Masala. Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tablespoons lemon juice\n",
      "- 2 teaspoons ground cumin\n",
      "- 2 teaspoons ground coriander\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon garam masala\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon chili powder (adjust to taste)\n",
      "- 3 cloves garlic, minced\n",
      "- 1 tablespoon grated ginger\n",
      "- Salt and pepper to taste\n",
      "- 2 tablespoons oil\n",
      "- 1 onion, diced\n",
      "- 1 can (14 oz) tomato sauce\n",
      "- 1 cup heavy cream\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, garam masala, paprika, chili powder, garlic, ginger, salt, and pepper. Add the chicken pieces and mix well to coat. Marinate for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Heat oil in a large skillet over medium-high heat. Add the diced onion and cook until softened, about 5 minutes.\n",
      "\n",
      "3. Add the marinated chicken pieces to the skillet, along with any excess marinade. Cook until the chicken is browned on all sides, about 5-7 minutes.\n",
      "\n",
      "4. Stir in the tomato sauce and bring to a simmer. Reduce heat to low, cover, and cook for 15-20 minutes, stirring occasionally.\n",
      "\n",
      "5. Stir in the heavy cream and simmer for an additional 5 minutes.\n",
      "\n",
      "6. Taste and adjust seasoning if needed. Serve the Chicken Tikka Masala over steamed rice, garnished with fresh cilantro.\n",
      "\n",
      "Enjoy your homemade Chicken Tikka Masala with naan bread or rice! Feel free to customize the spice level to suit your taste preferences.To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. One great option is to use paneer, which is a type of Indian cottage cheese that holds its shape well when cooked. Here's how you can prepare the paneer for this recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb paneer, cut into bite-sized cubes\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, garam masala, paprika, chili powder, garlic, ginger, salt, and pepper as per the original recipe.\n",
      "2. Add the paneer cubes to the marinade and mix gently to coat. Allow the paneer to marinate for at least 1 hour, or overnight for best results.\n",
      "3. Follow the remaining steps of the recipe as directed, substituting the marinated paneer for the chicken.\n",
      "4. When cooking the paneer in the skillet, be gentle to avoid breaking the cubes. Cook until the paneer is lightly browned on the edges.\n",
      "\n",
      "By using paneer as a replacement for chicken, you can enjoy a flavorful and satisfying vegetarian version of Chicken Tikka Masala. Serve it with rice or naan bread for a delicious meal!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Chicken Tikka Masala, we can replace the chicken with a suitable alternative. One great option is to use paneer, which is a type of Indian cottage cheese that holds its shape well when cooked. Here's how you can prepare the paneer for this recipe:\\n\\nIngredients:\\n- 1 lb paneer, cut into bite-sized cubes\\n\\nInstructions:\\n1. In a bowl, combine yogurt, lemon juice, cumin, coriander, turmeric, garam masala, paprika, chili powder, garlic, ginger, salt, and pepper as per the original recipe.\\n2. Add the paneer cubes to the marinade and mix gently to coat. Allow the paneer to marinate for at least 1 hour, or overnight for best results.\\n3. Follow the remaining steps of the recipe as directed, substituting the marinated paneer for the chicken.\\n4. When cooking the paneer in the skillet, be gentle to avoid breaking the cubes. Cook until the paneer is lightly browned on the edges.\\n\\nBy using paneer as a replacement for chicken, you can enjoy a flavorful and satisfying vegetarian version of Chicken Tikka Masala. Serve it with rice or naan bread for a delicious meal!\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modifiy the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain # \"recipe\" context object를 체인에 넣어줘 (아래 코드 안쓰고, recipe 값에 결과 저장 후, 다음 체인으로 전달)\n",
    "final_chain.invoke({ \n",
    "    \"cuisine\":\"indian\"\n",
    "})\n",
    "\n",
    "#\"recipe\": chef_chain 이것을 함으로서 자동으로 veg_chain.invoke() 가 돌아가는 것임\n",
    "\n",
    "# # 즉, chef_chain의 결과 {recipe}를 veg_chain의 input 으로..\n",
    "# veg_chain.invoke({\n",
    "#     \"recipe\":\"chatmodel\" #이런식으로\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모듈\n",
    "# LangChain은 다음과 같은 주요 모듈을 위한 확장 가능한 표준 인터페이스 및 외부 통합 기능을 제공합니다:\n",
    "\n",
    "# - Model I/O\n",
    "# 언어 모델과의 인터페이스\n",
    "\n",
    "# - Retrieval\n",
    "# 애플리케이션별 데이터를 사용한 인터페이스\n",
    "\n",
    "# - Agents\n",
    "# 높은 수준의 지침이 주어지면 체인이 어떤 도구를 사용할지 선택하도록 합니다\n",
    "\n",
    "# - Chains\n",
    "# 일반적인 빌딩 블록 구성\n",
    "\n",
    "# - Memory\n",
    "# 체인 실행 간 지속적인 응용 프로그램 상태\n",
    "\n",
    "# - Callbacks\n",
    "# 모든 체인의 중간 단계 기록 및 스트리밍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# few shot \n",
    "# you are giving examples to model how to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #이 형식도 똑같아 (langchain document way)\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatMessagePromptTemplate\n",
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1, # 낮을수록 창의적\n",
    "#     streaming=True,  # 실시간으로 글자 보여줘 \n",
    "#     callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "# t = PromptTemplate(\n",
    "#     template = \"What is the capital of {country}\",\n",
    "#     input_variables = ['country'])\n",
    "\n",
    "# t.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        Here is what I know:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate \n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "#format examples\n",
    "# example_template = \"\"\"Human: {question} AI : {answer}\"\"\"\n",
    "# example_prompt = PromptTemplate.from_template(example_template)\n",
    "# or just \n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI : {answer}\")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    "    suffix = \"Human: What do you know about {country}?\", #example 다 넣고, question of user\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "#prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"country\":\"Germany\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro\\n        ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatprompt templete 사용해보기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\", # 참고\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt =  ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"human\", \"What do you know about {country}?\"), #위 참고 가 country\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "chain.invoke({\"country\":\"Germany\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about France?\\n AI : \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Dynamic example selector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector # 예제의 양을 얼마나 되는지 확인하고, 세팅값에 따라 알맞은 prompt예제 골라줄 것임.\n",
    "\n",
    "        \n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 낮을수록 창의적\n",
    "    streaming=True,  # 실시간으로 글자 보여줘 \n",
    "    callbacks=[StreamingStdOutCallbackHandler()]) # console에 보이는 문자를 다 print해줘 (다양한 llm에서 일어나는 event를 감지하는 방법)\n",
    "\n",
    "#example\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\n AI : {answer}\")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate( \n",
    "    example_prompt = example_prompt,\n",
    "    example_selector=example_selector, #추가 (이제는 전체 예제를 사용하는게 아니라 selector를 거친 예제들만)\n",
    "    suffix = \"Human: What do you know about {country}?\", \n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country='Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about France?\\nAI:\\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Dynamic example selector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load the prompt templates from the disc. \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load the prompt templates from the disc. \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n    You are a role playing assistant.\\n    And you are impersonating a Pirate\\n\\n                                     \\n    \\n    This is an example of how you talk:\\n\\n    Human: What is your location?\\n    You: Arrrrg! That is a secret!! Arg arg!!\\n\\n                              \\n    \\n    Start now!\\n\\n    Human: What is your fav food?\\n    You:\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to compose many prompt together \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "#이거 끄고 아래꺼 돌려봐\n",
    "full_prompt.format(\n",
    "    character= \"Pirate\",\n",
    "    example_question= \"What is your location?\",\n",
    "    example_answer= \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "    question= \"What is your fav food?\",\n",
    ")\n",
    "\n",
    "\n",
    "# chain = full_prompt | chat\n",
    "\n",
    "# chain.invoke(\n",
    "#     {\n",
    "#         \"character\": \"Pirate\",\n",
    "#         \"example_question\": \"What is your location?\",\n",
    "#         \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "#         \"question\": \"What is your fav food?\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20079dd2ac21832bb0e8ff352d23b6c3837ca9c91609572aa5b291e173833a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
