{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt : 언어모델이 사용할 질문이나 명령을 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG Prompt structure :\n",
    "- Instruction \n",
    "- question\n",
    "- context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an AI assistant that performs Question-Answer (QA) tasks.\n",
    "Use the retrieved context to answer the question.\n",
    "If you cannot find the answer in the context, say \"I don't know.\"\n",
    "\n",
    "#Question:\n",
    "{The user's question will be inserted here}\n",
    "\n",
    "#Context:\n",
    "{The retrieved information will be inserted here}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Project1_Prompt\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"Project1_Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1. from_template() then PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm\n",
    "chain.invoke(\"대한민국\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2. PromptTemplate 객체 생성과 동시에 prompt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempalte = '{country} 의 수도는 어디인가요?'\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables=['country'],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country = '대한민국')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], partial_variables={'country2': '미국'}, template='{country1}과 {country2}의 수도는 각각 어디인가요?')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{country1}과 {country2}의 수도는 각각 어디인가요?\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"미국\"  # dictionary 형태로 partial_variables를 전달\n",
    "    },\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국과 미국의 수도는 각각 어디인가요?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country1=\"대한민국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], partial_variables={'country2': '캐나다'}, template='{country1}과 {country2}의 수도는 각각 어디인가요?')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(country2 = '캐나다')\n",
    "prompt_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국과 캐나다의 수도는 각각 어디인가요?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.format(country1=\"대한민국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울이고, 캐나다의 수도는 오타와입니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_partial | llm\n",
    "chain.invoke('대한민국').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울이며 호주의 수도는 캔버라입니다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country1\": \"대한민국\", \"country2\": \"호주\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## partial_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- partial을 사용하는 일반적인 용도는 함수를 부분적으로 사용하는 것. \n",
    "- 이 사용 사례는 항상 공통된 방식으로 가져오고 싶은 변수 가 있는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'August 21'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now().strftime(\"%B %d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is August 21. List 3 people who's birthday is today. Write Year-month-date.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Today's date is {today}. List {n} people who's birthday is today. Write Year-month-date.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        'today' : get_today\n",
    "    },\n",
    ")\n",
    "prompt.format(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Usain Bolt - 1986-08-21\n",
      "2. Hayden Panettiere - 1989-08-21\n",
      "3. Kim Cattrall - 1956-08-21\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "print(chain.invoke(3).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Vanessa Hudgens - 1988-12-14\n",
      "2. Tori Kelly - 1992-12-14\n",
      "3. KaDee Strickland - 1975-12-14\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"today\": \"Dec 14\", \"n\": 3}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate\n",
    "- 대화목록을 프롬프트로 주입하고자 할때 사용\n",
    "- tuple 형식, (role, message)\n",
    "- role : \n",
    "- system:\n",
    "    1. This role is used to provide initial instructions or set the context for the AI. It’s often used to define the behavior, personality, or specific instructions that the AI should follow during the conversation.\n",
    "    2. Example: \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\" tells the AI that it should act as a kind assistant and introduces the name variable.\n",
    "- human:\n",
    "    1. This role represents the input from the user or the human interacting with the AI. It simulates what the user would say or ask during the conversation.\n",
    "    2. Example: \"반가워요!\" and \"{user_input}\" are examples of what the human might say in this conversation.\n",
    "- ai:\n",
    "    1. This role represents the AI’s response. It’s the output generated by the AI based on the input from the human and the instructions provided by the system.\n",
    "    2. Example: \"안녕하세요! 무엇을 도와드릴까요?\" is how the AI responds to the user's greeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가?'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 대한민국의 수도는 어디인가?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 Chulwon 입니다.'),\n",
       " HumanMessage(content='반가워요!'),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?'),\n",
       " HumanMessage(content='당신의 이름은 무엇입니까?')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"Chulwon\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 Chulwon입니다. 필요하신 도움이 있으시면 언제든지 말씀해주세요!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 Chulwon입니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_template | llm\n",
    "chain.invoke({\"name\": \"Chulwon\", \"user_input\": \"당신의 이름은 무엇입니까?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MessagePlaceholder \n",
    "- Langchain은 포맷하는 동안 랜더링 할 메세지를 완전히 제어할수 있는 MessagePlaceholder제공\n",
    "- MessagePlaceholder is used within chat templates to create placeholders for dynamic content that will be filled in later when the template is rendered. \n",
    "- In other words, it allows you to define parts of a message that can be replaced with specific values when the conversation is being generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.')), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='지금까지의 대화를 {word_count} 단어로 요약합니다.'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\n",
      "Human: 안녕하세요! 저는 오늘 새로 입사한 철원 입니다. 만나서 반갑습니다.\n",
      "AI: 반가워요! 앞으로 잘 부탁 드립니다.\n",
      "Human: 지금까지의 대화를 5 단어로 요약합니다.\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 철원 입니다. 만나서 반갑습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신입 철원, 반가움 표현.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,\n",
    "        \"conversation\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"안녕하세요! 저는 오늘 새로 입사한 철원 입니다. 만나서 반갑습니다.\",\n",
    "            ),\n",
    "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20079dd2ac21832bb0e8ff352d23b6c3837ca9c91609572aa5b291e173833a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
